{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4807a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in d:\\ba870\\merge_preprocess\\venv\\lib\\site-packages (3.0.4)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in d:\\ba870\\merge_preprocess\\venv\\lib\\site-packages (from pydot) (3.2.3)\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df7a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating lag features: 100%|██████████| 10/10 [00:00<00:00, 37.27it/s]\n",
      "Computing rolling stats: 100%|██████████| 4/4 [00:00<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da8c9e43b3e4da681588c3b995894bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd75164c6114698aa37cfb9f2b63d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Bidirectional, LSTM, Dense, Dropout, concatenate\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "from tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# --- 1) LOAD & SORT\n",
    "df = pd.read_parquet('data/volume_pred.parquet')\n",
    "df = df.sort_values(['ticker','date']).reset_index(drop=True)\n",
    "\n",
    "# --- 2) LOG TARGET\n",
    "df['log_vol'] = np.log1p(df['VOL'])\n",
    "\n",
    "# --- 3) LAG FEATURES\n",
    "window = 10\n",
    "for lag in tqdm(range(1, window+1), desc='Creating lag features'):\n",
    "    df[f'lag_{lag}'] = df.groupby('ticker')['log_vol'].shift(lag)\n",
    "\n",
    "# --- 4) CALENDAR FEATURES\n",
    "df['weekday']        = df['date'].dt.weekday\n",
    "df['month']          = df['date'].dt.month\n",
    "df['is_month_end']   = df['date'].dt.is_month_end.astype(int)\n",
    "df['is_quarter_end'] = df['date'].dt.is_quarter_end.astype(int)\n",
    "\n",
    "# --- 5) ROLLING VOLUME STATS\n",
    "roll_specs = [\n",
    "    ('vol_ma_7',  7,  'mean'),\n",
    "    ('vol_ma_21',21, 'mean'),\n",
    "    ('vol_std_7', 7,  'std'),\n",
    "    ('vol_std_21',21, 'std')\n",
    "]\n",
    "for col_name, sz, func in tqdm(roll_specs, desc='Computing rolling stats'):\n",
    "    grp = df.groupby('ticker')['VOL']\n",
    "    if func == 'mean':\n",
    "        df[col_name] = grp.rolling(sz).mean().shift(1).reset_index(level=0,drop=True)\n",
    "    else:\n",
    "        df[col_name] = grp.rolling(sz).std().shift(1).reset_index(level=0,drop=True)\n",
    "\n",
    "# --- 6) DROP MISSING\n",
    "feat_cols = [f'lag_{i}' for i in range(1,window+1)] + [\n",
    "    'weekday','month','is_month_end','is_quarter_end',\n",
    "    'vol_ma_7','vol_ma_21','vol_std_7','vol_std_21'\n",
    "]\n",
    "df.dropna(subset=feat_cols + ['log_vol'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# --- 7) BUILD ARRAYS\n",
    "X_seq    = df[[f'lag_{i}' for i in range(1,window+1)]].values.reshape(-1, window, 1)\n",
    "X_static = df[['weekday','month','is_month_end','is_quarter_end',\n",
    "               'vol_ma_7','vol_ma_21','vol_std_7','vol_std_21']].values\n",
    "y_log    = df['log_vol'].values\n",
    "\n",
    "# helper to rebuild your model\n",
    "def build_model(window, n_static):\n",
    "    seq_in = Input(shape=(window,1), name='seq_input')\n",
    "    x_seq = Bidirectional(LSTM(64, return_sequences=True))(seq_in)\n",
    "    attn = MultiHeadAttention(num_heads=4, key_dim=64)(x_seq, x_seq)\n",
    "    x = GlobalAveragePooling1D()(attn)\n",
    "\n",
    "    st_in = Input(shape=(n_static,), name='static_input')\n",
    "    s = Dense(32, activation='relu')(st_in)\n",
    "    s = Dropout(0.2)(s)\n",
    "\n",
    "    m = concatenate([x, s])\n",
    "    m = Dense(64, activation='relu')(m)\n",
    "    m = Dropout(0.2)(m)\n",
    "    out = Dense(1, name='log_vol')(m)\n",
    "\n",
    "    model = Model([seq_in, st_in], out)\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# set up splits (time-series cross-validation (e.g. TimeSeriesSplit) for more robust error estimates                                                                    )\n",
    "n_splits = 5\n",
    "tscv     = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_seq), start=1):\n",
    "    print(f\"\\n=== Fold {fold}/{n_splits} ===\")\n",
    "\n",
    "    # ----- slice data -----\n",
    "    X_seq_tr, X_seq_te = X_seq[train_idx], X_seq[test_idx]\n",
    "    X_st_tr,  X_st_te  = X_static[train_idx], X_static[test_idx]\n",
    "    y_tr_log, y_te_log = y_log[train_idx],      y_log[test_idx]\n",
    "\n",
    "    # ----- scale -----\n",
    "    scaler_static = StandardScaler().fit(X_st_tr)\n",
    "    X_st_tr_s = scaler_static.transform(X_st_tr)\n",
    "    X_st_te_s = scaler_static.transform(X_st_te)\n",
    "\n",
    "    scaler_y = StandardScaler().fit(y_tr_log.reshape(-1,1))\n",
    "    y_tr_s   = scaler_y.transform(y_tr_log.reshape(-1,1))\n",
    "    y_te_s   = scaler_y.transform(y_te_log.reshape(-1,1))\n",
    "\n",
    "    # ----- TF datasets -----\n",
    "    train_ds = (\n",
    "        tf.data.Dataset\n",
    "          .from_tensor_slices(((X_seq_tr, X_st_tr_s), y_tr_s))\n",
    "          .batch(32)\n",
    "          .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    val_ds = (\n",
    "        tf.data.Dataset\n",
    "          .from_tensor_slices(((X_seq_te, X_st_te_s), y_te_s))\n",
    "          .batch(32)\n",
    "          .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # ----- build & train -----\n",
    "    model_cv = build_model(window, X_st_tr_s.shape[1])\n",
    "\n",
    "    # Save model architecture diagram to file\n",
    "    plot_model(model_cv, to_file=f'model_fold{fold}.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    es       = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model_cv.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=20,\n",
    "        callbacks=[es, TqdmCallback(verbose=1)],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # --- 13) PREDICTIONS & INVERT SCALING ----\n",
    "    y_pred_s   = model_cv.predict(val_ds).flatten()\n",
    "    y_pred_log = scaler_y.inverse_transform(y_pred_s.reshape(-1,1)).flatten()\n",
    "    y_base_log = X_seq_te[:,-1,0]  # persistence baseline\n",
    "\n",
    "    # --- 14) EVALUATION ---\n",
    "    # compute vol‐space metrics\n",
    "    y_true_vol = np.expm1(y_te_log)\n",
    "    y_pred_vol = np.expm1(y_pred_log)\n",
    "    y_base_vol = np.expm1(y_base_log)\n",
    "\n",
    "    print(f\"Fold {fold} — R² (log-space): {r2_score(y_te_log, y_pred_log):.4f}\")\n",
    "    print(f\"Fold {fold} — MSE (vol): {mean_squared_error(y_true_vol, y_pred_vol):.1f}\")\n",
    "    print(f\"Fold {fold} — MAE (vol): {mean_absolute_error(y_true_vol, y_pred_vol):.1f}\")\n",
    "    print(f\"Fold {fold} — R²  (vol): {r2_score(y_true_vol, y_pred_vol):.4f}\")\n",
    "    print(f\"Fold {fold} — Base R² (vol): {r2_score(y_true_vol, y_base_vol):.4f}\")\n",
    "\n",
    "    # --- 15) PLOT FIRST 200 (log-space) for this fold ---\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(y_te_log[:200],    label='True log_vol')\n",
    "    plt.plot(y_pred_log[:200], '--', label='Pred log_vol')\n",
    "    plt.legend()\n",
    "    plt.title(f\"Fold {fold} True vs Pred (first 200, log-space)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be808e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold  r2_log  r2_vol        mae\n",
      "0     1  0.9093  0.7611   938765.6\n",
      "1     2  0.9261  0.8205  1224918.0\n",
      "2     3  0.7178  0.7695  1145719.0\n",
      "3     4  0.9261  0.4957  1636971.0\n",
      "4     5  0.7344  0.8750  1372753.0\n",
      "          fold    r2_log    r2_vol           mae\n",
      "mean  3.000000  0.842740  0.744360  1.263825e+06\n",
      "std   1.581139  0.106859  0.146294  2.608782e+05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# example: replace these with your real numbers\n",
    "results = [\n",
    "    {'fold':1, 'r2_log':0.9093, 'r2_vol':0.7611, 'mae':938765.6},\n",
    "    {'fold':2, 'r2_log':0.9261, 'r2_vol':0.8205, 'mae':1224918.0},\n",
    "    {'fold':3, 'r2_log':0.7178, 'r2_vol':0.7695, 'mae':1145719.0},\n",
    "    {'fold':4, 'r2_log':0.9261, 'r2_vol':0.4957, 'mae':1636971.0},\n",
    "    {'fold':5, 'r2_log':0.7344, 'r2_vol':0.8750, 'mae':1372753.0}\n",
    "    # … folds 3–5 …\n",
    "]\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "summary = df_res.describe().loc[['mean','std']]\n",
    "print(df_res)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2edcd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_from_json\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 1) Serialize model to JSON + weights to a list\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model_json   = \u001b[43mmodel_cv\u001b[49m.to_json()\n\u001b[32m      6\u001b[39m model_weights= model_cv.get_weights()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 2) Bundle into a dict and pickle it\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model_cv' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# 1) Serialize model to JSON + weights to a list\n",
    "model_json   = model_cv.to_json()\n",
    "model_weights= model_cv.get_weights()\n",
    "\n",
    "# 2) Bundle into a dict and pickle it\n",
    "with open('vol_predictor.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model_json':   model_json,\n",
    "        'model_weights':model_weights\n",
    "    }, f)\n",
    "\n",
    "print(\"Saved model ✔ to vol_predictor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128463aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
